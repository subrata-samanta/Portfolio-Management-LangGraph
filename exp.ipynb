{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j AuraDB successfully\n",
      "output from extract_requirements: {'risk_tolerance': 'medium', 'time_horizon': 5, 'constraints': {'max_sector_allocation': {'tech': 25}, 'min_alternative_allocation': 20}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  13 of 13 completed\n",
      "[*********************100%***********************]  13 of 13 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output from analyze_risks:\n",
      " {'required_bond_allocation': 0.3, 'required_gold_allocation': 0.15, 'sector_risk_adjustments': {'Technology': 0.4, 'Healthcare': 0.25, 'Consumer Goods': 0.2, 'Financials': 0.15}, 'risk_scores': {'interest_rate_risk': 4, 'inflation_risk': 4, 'geopolitical_risk': 3, 'market_volatility': 2}, 'scenario_analysis': {'recession': {'expected_loss': 0.12, 'recommended_actions': ['Increase bond allocation to 0.4', 'Reduce exposure to high-risk sectors like Technology']}, 'rate_hike': {'expected_loss': 0.08, 'recommended_actions': ['Shift to shorter-duration bonds', 'Increase gold allocation to 0.2']}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'risk_tolerance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 390\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    385\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mOptimize portfolio for medium risk tolerance with:\u001b[39m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;124m    - Maximum 25\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m tech sector exposure\u001b[39m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;124m    - Minimum 20\u001b[39m\u001b[38;5;132;01m% a\u001b[39;00m\u001b[38;5;124mllocation to safe-haven assets\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124m    - 5-year investment horizon\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 390\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_portfolio_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPortfolio Recommendation:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[33], line 379\u001b[0m, in \u001b[0;36mrun_portfolio_analysis\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;66;03m# Run workflow\u001b[39;00m\n\u001b[0;32m    378\u001b[0m app \u001b[38;5;241m=\u001b[39m workflow\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m--> 379\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\Subrata Samanta\\miniconda3\\envs\\genai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2683\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2682\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2683\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2687\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2688\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2689\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2691\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2693\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Subrata Samanta\\miniconda3\\envs\\genai\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2331\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2326\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2330\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2335\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   2338\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Subrata Samanta\\miniconda3\\envs\\genai\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    144\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Subrata Samanta\\miniconda3\\envs\\genai\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Subrata Samanta\\miniconda3\\envs\\genai\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    603\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    604\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Subrata Samanta\\miniconda3\\envs\\genai\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 371\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[33], line 292\u001b[0m, in \u001b[0;36moptimize_portfolio\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    289\u001b[0m         ef\u001b[38;5;241m.\u001b[39madd_constraint(\u001b[38;5;28;01mlambda\u001b[39;00m w, si\u001b[38;5;241m=\u001b[39msector_indices: \u001b[38;5;28msum\u001b[39m(w[si]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_alloc)\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# Optimize based on risk tolerance\u001b[39;00m\n\u001b[1;32m--> 292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstraints\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrisk_tolerance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    293\u001b[0m     ef\u001b[38;5;241m.\u001b[39mmin_volatility()\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstraints\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrisk_tolerance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'risk_tolerance'"
     ]
    }
   ],
   "source": [
    "# File: portfolio_manager.py\n",
    "import os\n",
    "import json\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from typing import TypedDict\n",
    "from fredapi import Fred\n",
    "from sec_edgar_downloader import Downloader\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "\n",
    "# ----------------- Configuration -----------------\n",
    "FRED_API_KEY = os.getenv(\"FRED_API_KEY\")\n",
    "# AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_AUTH = (\"neo4j\", \"password\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "# Predefined portfolio constituents\n",
    "PORTFOLIO_SYMBOLS = [\n",
    "    'AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA',\n",
    "    'JNJ', 'PG', 'V', 'MA', 'NVDA',          # 10 stocks\n",
    "    'GLD',                                   # Gold ETF\n",
    "    'TLT', 'BND'                             # Bond ETFs\n",
    "]\n",
    "\n",
    "SYMBOL_SECTORS = {\n",
    "    # Stocks\n",
    "    'AAPL': 'Technology',\n",
    "    'MSFT': 'Technology',\n",
    "    'GOOG': 'Technology',\n",
    "    'AMZN': 'Consumer Discretionary',\n",
    "    'TSLA': 'Consumer Discretionary',\n",
    "    'JNJ': 'Healthcare',\n",
    "    'PG': 'Consumer Staples',\n",
    "    'V': 'Financials',\n",
    "    'MA': 'Financials',\n",
    "    'NVDA': 'Technology',\n",
    "    \n",
    "    # Alternative assets\n",
    "    'GLD': 'Commodity',\n",
    "    'TLT': 'Bonds',\n",
    "    'BND': 'Bonds'\n",
    "}\n",
    "\n",
    "GOLD_SYMBOL = 'GLD'\n",
    "BOND_SYMBOLS = ['TLT', 'BND']\n",
    "\n",
    "# Initialize services\n",
    "fred = Fred(api_key=FRED_API_KEY)\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-qwen-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "# ----------------- Enhanced Data Ingestion -----------------\n",
    "class DataIngestor:\n",
    "    @staticmethod\n",
    "    def get_market_data(period: str = \"3y\"):\n",
    "        \"\"\"Fetch historical prices for all portfolio assets\"\"\"\n",
    "        return yf.download(PORTFOLIO_SYMBOLS, period=period,auto_adjust=False)['Adj Close']\n",
    "\n",
    "    @staticmethod\n",
    "    def get_economic_data():\n",
    "        \"\"\"Fetch key economic indicators from FRED\"\"\"\n",
    "        return {\n",
    "            'DGS10': fred.get_series('DGS10'),   # 10-Year Treasury Rate\n",
    "            'CPI': fred.get_series('CPIAUCSL'),  # Consumer Price Index\n",
    "            'UNRATE': fred.get_series('UNRATE'), # Unemployment Rate\n",
    "            'GFDEBTN': fred.get_series('GFDEBTN') # Federal Debt\n",
    "        }\n",
    "\n",
    "# ----------------- Enhanced Knowledge Graph -----------------\n",
    "class FinancialKG:\n",
    "    def __init__(self):\n",
    "        self.graph = Neo4jGraph(\n",
    "            url=os.getenv(\"NEO4J_URI\"),\n",
    "            username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "            password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    "            database=\"neo4j\",  # Default database\n",
    "            # aura_instance_id=os.getenv(\"AURA_INSTANCEID\"),\n",
    "            # aura_instance_name=os.getenv(\"AURA_INSTANCENAME\")\n",
    "        )\n",
    "        \n",
    "        # Verify connection\n",
    "        try:\n",
    "            self.graph.query(\"RETURN 1 AS test\")\n",
    "            print(\"Connected to Neo4j AuraDB successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Connection failed: {str(e)}\")\n",
    "\n",
    "    def create_asset_node(self, symbol: str):\n",
    "        self.graph.query(\n",
    "            \"\"\"MERGE (a:Asset {symbol: $symbol})\n",
    "            RETURN a\"\"\",\n",
    "            params={\"symbol\": symbol}\n",
    "        )\n",
    "\n",
    "    def link_risk_factors(self, symbol: str, risk_data: dict):\n",
    "        self.graph.query(\n",
    "            \"\"\"MATCH (a:Asset {symbol: $symbol})\n",
    "            MERGE (r:Risk {name: $risk_name})\n",
    "            MERGE (a)-[rel:EXPOSED_TO]->(r)\n",
    "            SET rel.score = $score\"\"\",\n",
    "            params={\n",
    "                \"symbol\": symbol,\n",
    "                \"risk_name\": risk_data['name'],\n",
    "                \"score\": risk_data['score']\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def create_portfolio_structure(self):\n",
    "        \"\"\"Initialize portfolio nodes and relationships\"\"\"\n",
    "        # Create asset classes\n",
    "        self.graph.query(\"\"\"\n",
    "            MERGE (:AssetClass {name: 'Equities'})\n",
    "            MERGE (:AssetClass {name: 'Fixed Income'})\n",
    "            MERGE (:AssetClass {name: 'Commodities'})\n",
    "        \"\"\")\n",
    "        \n",
    "        # Link assets to classes\n",
    "        for symbol in PORTFOLIO_SYMBOLS:\n",
    "            asset_class = 'Commodities' if symbol == GOLD_SYMBOL else \\\n",
    "                        'Fixed Income' if symbol in BOND_SYMBOLS else \\\n",
    "                        'Equities'\n",
    "            self.graph.query(\n",
    "                \"\"\"\n",
    "                MERGE (a:Asset {symbol: $symbol})\n",
    "                MERGE (c:AssetClass {name: $class})\n",
    "                MERGE (a)-[:BELONGS_TO]->(c)\n",
    "                \"\"\",\n",
    "                params={\"symbol\": symbol, \"class\": asset_class}\n",
    "            )\n",
    "# ----------------- Enhanced LangGraph Workflow -----------------\n",
    "class PortfolioState(TypedDict):\n",
    "    user_query: str\n",
    "    symbols: list\n",
    "    economic_data: dict\n",
    "    market_data: pd.DataFrame\n",
    "    risk_factors: dict\n",
    "    constraints: dict\n",
    "    weights: dict\n",
    "\n",
    "def extract_requirements(state: PortfolioState):\n",
    "    # Safely get query from state\n",
    "    user_query = state.get(\"user_query\", \"\")\n",
    "    \n",
    "    template = \"\"\"Analyze portfolio request and extract:\n",
    "    {query}\n",
    "\n",
    "    Return JSON with:\n",
    "    - risk_tolerance: low/medium/high\n",
    "    - time_horizon: years\n",
    "    - constraints: {{\n",
    "        max_sector_allocation: {{sector: max_percent}},\n",
    "        min_alternative_allocation: percentage\n",
    "    }}\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=template,\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()})\n",
    "    \n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    response = chain.invoke({\"query\": user_query})\n",
    "\n",
    "    print(\"output from extract_requirements:\", response)\n",
    "    \n",
    "    # response = llm.invoke(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "def analyze_risks(state: PortfolioState):\n",
    "    template_risk = \"\"\"Analyze market risks for a portfolio containing {symbols} given:\n",
    "    Economic Indicators: {econ_data}\n",
    "    1-Year Volatility: {volatility}\n",
    "    \n",
    "    Output JSON with:\n",
    "    1. required_bond_allocation (0-1)\n",
    "    2. required_gold_allocation (0-1) \n",
    "    3. sector_risk_adjustments (sector: max_allocation)\n",
    "    4. risk_scores (1-5 scale)\n",
    "    5. scenario_analysis (recession/rate_hike cases)\n",
    "\n",
    "    format should be like this-\n",
    "\n",
    "    dict : {{\n",
    "            \"required_bond_allocation\": float (0-1),\n",
    "            \"required_gold_allocation\": float (0-1),\n",
    "            \"sector_risk_adjustments\": {{\n",
    "                \"Technology\": float (0-1),\n",
    "                \"Healthcare\": float (0-1),\n",
    "                ...\n",
    "            }},\n",
    "            \"risk_scores\": {{\n",
    "                \"interest_rate_risk\": int (1-5),\n",
    "                \"inflation_risk\": int (1-5),\n",
    "                \"geopolitical_risk\": int (1-5),\n",
    "                \"market_volatility\": int (1-5)\n",
    "            }},\n",
    "            \"scenario_analysis\": {{\n",
    "                \"recession\": {{\n",
    "                    \"expected_loss\": float (0-1),\n",
    "                    \"recommended_actions\": list[str]\n",
    "                }},\n",
    "                \"rate_hike\": {{\n",
    "                    \"expected_loss\": float (0-1),\n",
    "                    \"recommended_actions\": list[str]\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "    template=template_risk,\n",
    "    input_variables=[\"econ_data\", \"econ_data\", \"volatility\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    econ_data = {k: v.iloc[-1] for k, v in state[\"economic_data\"].items()}\n",
    "    volatility = state[\"market_data\"].pct_change().std().mean()\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    response = chain.invoke({\"symbols\":PORTFOLIO_SYMBOLS,\"econ_data\": econ_data, \"volatility\": volatility})\n",
    "    \n",
    "    # response = llm.invoke(prompt.format(\n",
    "    #     symbols=PORTFOLIO_SYMBOLS,\n",
    "    #     econ_data=econ_data,\n",
    "    #     volatility=round(volatility, 4)\n",
    "    # ))\n",
    "\n",
    "    print(\"output from analyze_risks:\\n\", response)\n",
    "    return {\"risk_factors\": response}\n",
    "\n",
    "def optimize_portfolio(state: PortfolioState):\n",
    "    prices = state[\"market_data\"]\n",
    "    returns = expected_returns.mean_historical_return(prices)\n",
    "    cov_matrix = risk_models.exp_cov(prices)\n",
    "    \n",
    "    ef = EfficientFrontier(returns, cov_matrix)\n",
    "    \n",
    "    # Basic diversification constraint\n",
    "    ef.add_constraint(lambda w: w <= 0.15)  # Max 15% per stock\n",
    "    \n",
    "    # Add bond allocation constraint\n",
    "    bond_indices = [i for i, s in enumerate(PORTFOLIO_SYMBOLS) if s in BOND_SYMBOLS]\n",
    "    if bond_indices:\n",
    "        ef.add_constraint(lambda w: sum(w[i] for i in bond_indices) >= \n",
    "                         state[\"risk_factors\"][\"required_bond_allocation\"])\n",
    "    \n",
    "    # Add gold allocation constraint\n",
    "    if GOLD_SYMBOL in PORTFOLIO_SYMBOLS:\n",
    "        gold_index = PORTFOLIO_SYMBOLS.index(GOLD_SYMBOL)\n",
    "        ef.add_constraint(lambda w: w[gold_index] >= \n",
    "                         state[\"risk_factors\"][\"required_gold_allocation\"])\n",
    "    \n",
    "    # Sector constraints from both user and risk analysis\n",
    "    sector_map = [SYMBOL_SECTORS[s] for s in PORTFOLIO_SYMBOLS]\n",
    "    for sector, max_alloc in {**state[\"constraints\"][\"max_sector_allocation\"],\n",
    "                              **state[\"risk_factors\"][\"sector_risk_adjustments\"]}.items():\n",
    "        sector_indices = [i for i, s in enumerate(sector_map) if s == sector]\n",
    "        if sector_indices:\n",
    "            ef.add_constraint(lambda w, si=sector_indices: sum(w[si]) <= max_alloc)\n",
    "    \n",
    "    # Optimize based on risk tolerance\n",
    "    if state[\"constraints\"][\"risk_tolerance\"] == 'low':\n",
    "        ef.min_volatility()\n",
    "    elif state[\"constraints\"][\"risk_tolerance\"] == 'medium':\n",
    "        ef.max_sharpe()\n",
    "    else:\n",
    "        target_return = returns.mean() * 1.2  # 20% higher than average\n",
    "        ef.efficient_return(target_return)\n",
    "    \n",
    "    return {\"weights\": ef.clean_weights()}\n",
    "\n",
    "def generate_report(state: PortfolioState):\n",
    "    prompt = \"\"\"Generate comprehensive portfolio analysis report with:\n",
    "    - Current market risk assessment\n",
    "    - Asset allocation rationale\n",
    "    - Stress test scenarios\n",
    "    - Rebalancing recommendations\n",
    "    \n",
    "    Portfolio Details:\n",
    "    {weights}\n",
    "    \n",
    "    Risk Factors:\n",
    "    {risk_factors}\n",
    "    \n",
    "    Economic Context:\n",
    "    {econ_data}\"\"\"\n",
    "    \n",
    "    econ_data = \"\\n\".join([f\"{k}: {v.iloc[-1]:.2f}\" \n",
    "                         for k, v in state[\"economic_data\"].items()])\n",
    "    \n",
    "    response = llm.invoke(prompt.format(\n",
    "        weights=json.dumps(state[\"weights\"], indent=2),\n",
    "        risk_factors=json.dumps(state[\"risk_factors\"], indent=2),\n",
    "        econ_data=econ_data\n",
    "    ))\n",
    "\n",
    "    return {\"report\": response.content}\n",
    "\n",
    "# ----------------- Workflow Setup -----------------\n",
    "workflow = StateGraph(PortfolioState)\n",
    "\n",
    "workflow.add_node(\"ingest_data\", lambda s: {\n",
    "    \"market_data\": DataIngestor.get_market_data(),\n",
    "    \"economic_data\": DataIngestor.get_economic_data()\n",
    "})\n",
    "\n",
    "workflow.add_node(\"analyze_risks\", analyze_risks)\n",
    "workflow.add_node(\"optimize\", optimize_portfolio)\n",
    "workflow.add_node(\"generate_report\", generate_report)\n",
    "\n",
    "workflow.set_entry_point(\"ingest_data\")\n",
    "workflow.add_edge(\"ingest_data\", \"analyze_risks\")\n",
    "workflow.add_edge(\"analyze_risks\", \"optimize\")\n",
    "workflow.add_edge(\"optimize\", \"generate_report\")\n",
    "workflow.add_edge(\"generate_report\", END)\n",
    "\n",
    "# ----------------- Execution -----------------\n",
    "def run_portfolio_analysis(query: str):\n",
    "    kg = FinancialKG()\n",
    "    kg.create_portfolio_structure()\n",
    "    \n",
    "    # Initialize state with all required fields\n",
    "    state = {\n",
    "        \"user_query\": query,\n",
    "        \"symbols\": PORTFOLIO_SYMBOLS,\n",
    "        \"economic_data\": {},\n",
    "        \"market_data\": pd.DataFrame(),\n",
    "        \"risk_factors\": {},\n",
    "        \"constraints\": {},\n",
    "        \"weights\": {}\n",
    "    }\n",
    "    \n",
    "    # Add this verification step\n",
    "    if \"user_query\" not in state:\n",
    "        raise ValueError(\"State missing required 'user_query' field\")\n",
    "        \n",
    "    # Extract and merge requirements\n",
    "    requirements = extract_requirements(state)\n",
    "    state.update(requirements)\n",
    "    \n",
    "    # Add data ingestion to workflow\n",
    "    state.update({\n",
    "        \"market_data\": DataIngestor.get_market_data(),\n",
    "        \"economic_data\": DataIngestor.get_economic_data()\n",
    "    })\n",
    "    \n",
    "    # Run workflow\n",
    "    app = workflow.compile()\n",
    "    results = app.invoke(state)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"\"\"Optimize portfolio for medium risk tolerance with:\n",
    "    - Maximum 25% tech sector exposure\n",
    "    - Minimum 20% allocation to safe-haven assets\n",
    "    - 5-year investment horizon\"\"\"\n",
    "    \n",
    "    result = run_portfolio_analysis(query)\n",
    "    print(\"\\nPortfolio Recommendation:\")\n",
    "    print(result[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
